{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcf1ff24",
   "metadata": {},
   "source": [
    "# Spark SQL Básico\n",
    "\n",
    "Spark SQL es el módulo de Apache Spark para trabajar con datos estructurados (esquema definido). Permite ejecutar consultas SQL o usar una API estilo SQL (como .select, .where, etc.) sobre DataFrames, tanto en lenguaje SQL como en APIs de alto nivel (PySpark, Scala, etc.). En este laboratorio, nos centraremos únicamente en consultas mediante lenguaje SQL y la creación de vistas temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb58a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "# Crear la sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"PySpark05\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9453b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"Alice\", \"HR\", 3000),\n",
    "    (\"Bob\", \"IT\", 4500),\n",
    "    (\"Cathy\", \"HR\", 3200),\n",
    "    (\"David\", \"IT\", 5000),\n",
    "    (\"Eve\", \"Finance\", 4000)\n",
    "]\n",
    "columns = [\"name\", \"department\", \"salary\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3add93",
   "metadata": {},
   "source": [
    "## Vistas temporales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9b0182",
   "metadata": {},
   "source": [
    "Las vistas temporales (temp views) son una forma de registrar un DataFrame como una tabla SQL temporal en la sesión de Spark. Esto permite usar SQL sobre cualquier DataFrame que ya hayas cargado o transformado. Esto no guarda nada en disco, y solo vive mientras dure la sesión de Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2625f3db",
   "metadata": {},
   "source": [
    "Existe una variante que no se borra al cerrar la sesión, sino que se comparte entre sesiones Spark:\n",
    "```python\n",
    "df.createGlobalTempView(\"nombre_global\")\n",
    "spark.sql(\"SELECT * FROM global_temp.nombre_global\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52541f",
   "metadata": {},
   "source": [
    "##### ¿Cuándo usar vistas temporales?\n",
    "- Cuando vienes del mundo SQL y te es más natural escribir consultas.\n",
    "- Cuando quieres dividir la lógica de procesamiento en etapas (puedes crear una vista para cada paso).\n",
    "- Cuando compartes lógica entre scripts o notebooks y necesitas una \"tabla virtual\" común.\n",
    "- Cuando haces prototipado rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8907b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una vista temporal\n",
    "df.createOrReplaceTempView(\"employees\")\n",
    "\n",
    "# Ejecutar consulta SQL\n",
    "result = spark.sql(\"SELECT department, AVG(salary) AS avg_salary FROM employees GROUP BY department\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d606006",
   "metadata": {},
   "source": [
    "## Funciones integradas y expresiones SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb60934",
   "metadata": {},
   "source": [
    "Con Spark, podemos lanzar consultas SQL directamente como una query sin tener que traducirla a PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa43fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtros y orden\n",
    "spark.sql(\"SELECT name, salary FROM employees WHERE salary > 3500 ORDER BY salary DESC\").show()\n",
    "\n",
    "# Conteo por categoría\n",
    "spark.sql(\"SELECT department, COUNT(*) as count FROM employees GROUP BY department\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac820437",
   "metadata": {},
   "source": [
    "Spark permite aplicar funciones como: AVG, COUNT, SUM, DATEDIFF, CASE WHEN, ROUND, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a3f186",
   "metadata": {},
   "source": [
    "## Equivalente en código Python (API DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a31ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df.salary > 3500).select(\"name\", \"salary\").orderBy(\"salary\", ascending=False).show()\n",
    "df.groupBy('department').agg(f.count('*').alias('num_employees')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b93a90",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "\n",
    "1. Carga el archivo *../data/taxi_zone_lookup.csv* que contiene datos relacionados con zonas de recogida de taxis y crea una vista temporal\n",
    "2. Contesta a las preguntas:\n",
    "    - ¿Cuántas zonas hay por cada borough?\n",
    "    - ¿Cuántos LocationID hay por zona de servicio?\n",
    "3. Compara las mismas operaciones usando la API de DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69942366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos relacionados con zonas de recogida de taxis\n",
    "df = spark.read.option(\"header\", True).csv(\"../../data/taxi_zone_lookup.csv\")\n",
    "\n",
    "# Ver las primeras filas\n",
    "df.show(5)\n",
    "# Esquema del DataFrame\n",
    "df.printSchema()\n",
    "\n",
    "df.createOrReplaceTempView(\"taxi_zones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5753fdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Cuántas zonas hay por cada borough?\n",
    "spark.sql(\"\"\"\n",
    "    SELECT Borough, COUNT(DISTINCT Zone) AS num_zones\n",
    "    FROM taxi_zones\n",
    "    GROUP BY Borough\n",
    "    ORDER BY num_zones DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a662f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Cuántos LocationID hay por zona de servicio?\n",
    "spark.sql(\"\"\"\n",
    "    SELECT service_zone, COUNT(*) AS location_count\n",
    "    FROM taxi_zones\n",
    "    GROUP BY service_zone\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1241c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Cuántas zonas hay por cada borough?\n",
    "df.groupBy('Borough').agg(f.countDistinct('Zone').alias('zones')).orderBy('zones', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2015dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Cuántos LocationID hay por zona de servicio?\n",
    "df.groupBy('service_zone').agg(f.count('*').alias('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec039bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
