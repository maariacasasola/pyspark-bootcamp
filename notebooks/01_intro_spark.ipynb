{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90e7b2cd",
   "metadata": {},
   "source": [
    "# Get Started con PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15b9dc6",
   "metadata": {},
   "source": [
    "### Preparando el entorno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810e48cb",
   "metadata": {},
   "source": [
    "Vamos a importar los paquetes de python que son necesarios y abrir una sesión de Spark. Puedes nombrarla como quieras, elijo 'PySpark01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9177a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Crear sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"PySparkShell\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f717ffd4",
   "metadata": {},
   "source": [
    "### Primeros pasos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76abab4",
   "metadata": {},
   "source": [
    "Estas son algunas transformaciones rápidas que PySpark te permite aplicar sobre tus datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d14622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer archivo CSV\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"../data/movies.csv\")\n",
    "\n",
    "df.printSchema()\n",
    "df.show(5)\n",
    "\n",
    "# Conteo total de registros\n",
    "print(\"Total de películas:\", df.count())\n",
    "\n",
    "# Filtrar y seleccionar columnas\n",
    "df_filtered = df.select(\"title\", \"genre\", \"rating\").filter(col(\"rating\") > 8.5)\n",
    "\n",
    "# Agrupación por género\n",
    "df_grouped = df_filtered.groupBy(\"genre\").agg(avg(\"rating\").alias(\"avg_rating\"))\n",
    "df_grouped.orderBy(col(\"avg_rating\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5145008b",
   "metadata": {},
   "source": [
    "### Particiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57051d59",
   "metadata": {},
   "source": [
    "Usando Spark, podemos particionar los datos por una o más columnas. Cuando particionamos un conjunto de datos, lo estamos dividiendo en varios archivos. Por lo tanto, podemos leer solo una partición relevante cuando nos interese, y no todos los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4fe934",
   "metadata": {},
   "source": [
    "Un archivo Parquet es un formato de archivo columnar utilizado para almacenar datos de una manera eficiente y optimizada. En lugar de guardar los datos en filas (como un archivo CSV o una tabla tradicional), Parquet los organiza por columnas, lo que permite consultas y análisis más rápidos, especialmente cuando se manejan grandes volúmenes de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ed1f3f",
   "metadata": {},
   "source": [
    "Un buen ejemplo útil de dividir nuestros datos sería por la columna 'año', o las columnas 'año' y 'mes', si corresponde. De esta manera, podríamos acceder a un conjunto de datos correspondientes a una fecha específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9b0984",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aplicar función de ventana: Top 3 películas por género según mejor valoración\n",
    "window_spec = Window.partitionBy(\"genre\").orderBy(col(\"rating\").desc())\n",
    "df_with_rank = df_filtered.withColumn(\"rank\", row_number().over(window_spec))\n",
    "\n",
    "df_top3 = df_with_rank.filter(col(\"rank\") <= 3)\n",
    "df_top3.show()\n",
    "\n",
    "# Guardar resultado en formato Parquet\n",
    "df_top3.write.mode(\"overwrite\").parquet(\"data/top_movies_by_genre.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6092720c",
   "metadata": {},
   "source": [
    "### Detener la sesión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e6a22c",
   "metadata": {},
   "source": [
    "Finalmente, como las mejores prácticas nos enseñan, debemos detener la sesión de Spark. Eso significa que liberamos todos los recursos asignados a nuestra sesión de Spark (memoria, conexiones, pojects, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detener la sesión de Spark\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
