{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e9ecd25",
   "metadata": {},
   "source": [
    "# User Defined Functions (UDFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d487481a",
   "metadata": {},
   "source": [
    "Un UDF (User Defined Function) te permite crear una funci√≥n personalizada en Python (o Scala, etc.) que se puede usar en expresiones SQL o DataFrame API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6886c3f",
   "metadata": {},
   "source": [
    "##### Configuraci√≥n del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879e5723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"PySpark04\").getOrCreate()\n",
    "# Cargar el dataset de viajes\n",
    "yellow_df = spark.read.parquet(\"../../data/yellow_tripdata_2023-01.parquet\")\n",
    "yellow_df.createOrReplaceTempView(\"yellow_trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135bdf1a",
   "metadata": {},
   "source": [
    "#### Creaci√≥n y aplicaci√≥n de una UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af940dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define una funci√≥n en Python\n",
    "def clasificar_viaje(distancia):\n",
    "    if distancia < 2:\n",
    "        return 'short'\n",
    "    elif distancia <= 10:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'long'\n",
    "\n",
    "# Se registra como UDF\n",
    "clasificar_udf = udf(clasificar_viaje, StringType())\n",
    "\n",
    "# Se aplica a un DataFrame\n",
    "df = yellow_df.withColumn(\"trip_type\", clasificar_udf(\"trip_distance\"))\n",
    "df.select(\"trip_distance\", \"trip_type\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd7a702",
   "metadata": {},
   "source": [
    "Tambi√©n puedes registrarla para usarla en SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cee6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.udf.register(\"clasificar_udf\", clasificar_viaje, StringType())\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT trip_distance, clasificar_udf(trip_distance) AS trip_type\n",
    "    FROM yellow_trips\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d72ee",
   "metadata": {},
   "source": [
    "## Persistencia de UDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add94d8a",
   "metadata": {},
   "source": [
    "Las UDFs en PySpark se definen y viven en la sesi√≥n actual del SparkSession o script donde se crean. No se persisten autom√°ticamente en disco ni entre sesiones, como podr√≠a pasar con una funci√≥n SQL en una base de datos relacional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab12ad42",
   "metadata": {},
   "source": [
    "Sin embargo, cuando trabajas a nivel de producci√≥n con Spark en cl√∫steres (como Databricks o EMR), puedes definir UDFs como funciones registradas en un paquete JAR, y cargarlas como funciones permanentes en Hive Metastore.\n",
    "\n",
    "üëâ Esto es m√°s com√∫n con UDFs escritas en Scala (m√°s eficientes que las de Python)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc0d845",
   "metadata": {},
   "source": [
    "## Buenas pr√°cticas con UDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0862e687",
   "metadata": {},
   "source": [
    "En un enfoque est√°ndar de ingenier√≠a de datos, es muy com√∫n crear un archivo _.py_ (Por ejemplo: _utils.py_) para reutilizar el c√≥digo de las funciones en distintas sesiones. Sin tener que escribirlo en cada notebook.\n",
    "\n",
    "Simplemente tendr√≠amos que llamar a la funci√≥n que queremos importar desde cada notebook de la siguiente manera:\n",
    "\n",
    "```python\n",
    "from utils.py import clasificar_udf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ca3a9f",
   "metadata": {},
   "source": [
    "\n",
    "Nuestro archivo _utils.py_ tendr√≠a un aspecto similar a este:\n",
    "```python\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def clasificar_viaje(distancia):\n",
    "    if distancia < 2:\n",
    "        return 'short'\n",
    "    elif distancia <= 10:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'long'\n",
    "\n",
    "clasificar_udf = udf(clasificar_viaje, StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fb1021",
   "metadata": {},
   "source": [
    "## Puntos clave de Spark SQL vs. API DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c14c42",
   "metadata": {},
   "source": [
    "| Spark SQL                                    | DataFrame API                                    |\n",
    "| -------------------------------------------- | ------------------------------------------------ |\n",
    "| Muy familiar si vienes de SQL                | M√°s expresivo y flexible en l√≥gica compleja      |\n",
    "| √ötil para prototipar y explorar              | Mejores herramientas de depuraci√≥n en Python     |\n",
    "| Puedes usar `.sql()` sobre vistas temporales | Puedes encadenar transformaciones m√°s f√°cilmente |\n",
    "| Igual de optimizado (Catalyst optimizer)     | Igual de r√°pido                                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6038fca",
   "metadata": {},
   "source": [
    "Ambos se compilan al mismo plan l√≥gico, as√≠ que rendimiento ‚âà igual.\n",
    "Es m√°s una cuesti√≥n de preferencia y legibilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f4fa36",
   "metadata": {},
   "source": [
    "##### Detenemos la sesi√≥n de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a23e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
