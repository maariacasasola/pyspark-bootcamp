{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1e5a458",
   "metadata": {},
   "source": [
    "## Spark SQL y vistas temporales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd49163c",
   "metadata": {},
   "source": [
    "### Retos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90682a2b",
   "metadata": {},
   "source": [
    "**Contesta a las siguientes preguntas usando solamente SparkSQL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e611a3",
   "metadata": {},
   "source": [
    "1. Crea vistas temporales para trabajar con los dos conjuntos de datos cargados.\n",
    "2. ¿Cuáles son las 5 zonas con más viajes iniciados?\n",
    "    + Tips:\n",
    "        -  JOIN con PULocationID\n",
    "        - Agrupa por zona\n",
    "        - Cuenta viajes\n",
    "3. ¿Cuál es la propina promedio (tip_amount) para cada zona de destino?\n",
    "    + Tips:\n",
    "        - JOIN con DOLocationID\n",
    "        - Agrupa por zona\n",
    "        - Ordena de mayor a menor\n",
    "4. ¿Qué zonas tienen los viajes más duraderos en promedio?\n",
    "    + Tips:\n",
    "        - JOIN con PULocationID\n",
    "        - Agrupa por zona\n",
    "        - Calcula diferencia entre momento de salida y momento de llegada\n",
    "5. ¿Cuántos viajes hubo por Borough de origen y por franja horaria (mañana/tarde/noche/madrugada)?\n",
    "    + Tips:\n",
    "        - JOIN con PULocationID + taxi_zones\n",
    "        - Extrae hora del tpep_pickup_datetime\n",
    "        - Crea CASE para categorizar horarios:\n",
    "            ```sql\n",
    "            CASE \n",
    "                WHEN hour BETWEEN 5 AND 11 THEN 'mañana'\n",
    "                WHEN hour BETWEEN 12 AND 17 THEN 'tarde'\n",
    "                WHEN hour BETWEEN 18 AND 23 THEN 'noche'\n",
    "                ELSE 'madrugada'\n",
    "            END AS franja\n",
    "            ```\n",
    "        - Agrupa por borough y franja\n",
    "6. ¿Qué zonas (de recogida) generan más ingresos totales (total_amount)?\n",
    "    + Tips:\n",
    "        - JOIN con PULocationID\n",
    "        - Agrupa por zona\n",
    "        - SUM del total_amount\n",
    "        - Filtra zonas con al menos 10.000 viajes (usa HAVING)\n",
    "7. Calcula el desvío estándar de tip_amount por zona de destino, y encuentra las zonas con más variación.\n",
    "    + Tips:\n",
    "        - Usa STDDEV(tip_amount)\n",
    "        - JOIN con DOLocationID\n",
    "        - Ordena de mayor a menor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82c56f0",
   "metadata": {},
   "source": [
    "Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f85da3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Crear la sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"PySpark03-challenge\").getOrCreate()\n",
    "\n",
    "# Cargar datos\n",
    "taxi_zones = spark.read.option(\"header\", True).csv(\"../../data/taxi_zone_lookup.csv\")\n",
    "trips_df = spark.read.parquet(\"../../data/yellow_tripdata_2023-01.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9aa611",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db89ab23",
   "metadata": {},
   "source": [
    "Apartado 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d5112a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zones.createOrReplaceTempView(\"taxi_zones\")\n",
    "trips_df.createOrReplaceTempView(\"yellow_trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zones.show(5)\n",
    "trips_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76d6e43",
   "metadata": {},
   "source": [
    "Apartado 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT z.Zone AS pickup_zone, COUNT(*) AS num_trips\n",
    "    FROM yellow_trips t\n",
    "    JOIN taxi_zones z\n",
    "    ON t.PULocationID = z.LocationID\n",
    "    GROUP BY z.Zone\n",
    "    ORDER BY num_trips DESC\n",
    "    LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dac1a19",
   "metadata": {},
   "source": [
    "Apartado 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa3e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT z.Zone AS dropoff_zone, AVG(tip_amount) AS prom_tips\n",
    "    FROM yellow_trips t\n",
    "    JOIN taxi_zones z\n",
    "    ON t.DOLocationID = z.LocationID\n",
    "    GROUP BY z.Zone\n",
    "    ORDER BY prom_tips DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae9b993",
   "metadata": {},
   "source": [
    "Apartado 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b34bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT z.Zone AS pickup_zone, \n",
    "       AVG((unix_timestamp(t.tpep_dropoff_datetime) - unix_timestamp(t.tpep_pickup_datetime)) / 60.0) AS prom_trip_dur_min\n",
    "    FROM yellow_trips t\n",
    "    JOIN taxi_zones z\n",
    "    ON t.PULocationID = z.LocationID\n",
    "    GROUP BY z.Zone\n",
    "    ORDER BY prom_trip_dur_min DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680a539",
   "metadata": {},
   "source": [
    "¿Podríamos usar la siguiente consulta?\n",
    "```python\n",
    "spark.sql(\"\"\"\n",
    "    SELECT z.Zone AS pickup_zone, \n",
    "    AVG(DATEDIFF(minute, tpep_pickup_datetime, tpep_dropoff_datetime)) AS prom_trip_dur_min\n",
    "    FROM yellow_trips t\n",
    "    JOIN taxi_zones z\n",
    "    ON t.PULocationID = z.LocationID\n",
    "    GROUP BY z.Zone\n",
    "    ORDER BY prom_trip_dur_min DESC\n",
    "\"\"\").show()\n",
    "```\n",
    "\n",
    "**En este entorno sí**, ya que probablemente esta consulta nos devuelva un resultado correcto y similar a la de arriba. Sin embargo, hay que tener en cuenta que este entorno Dockerizado está configurado a partir de una imagen predefinida (de Internet), por lo que seguramente cuente con alguna expensión adicional que añada un parsing flexible o compatibilidad extra.\n",
    "\n",
    "Comento esto porque es interesante saber que la forma \"canónica\" en Spark SQL es la primera, que usa el método explícito \"unix_timestamp()\". Ten en mente que si corres ese mismo código en Apache Spark sin extensiones (por ejemplo en un cluster crudo o en PySpark CLI), puede fallar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beba14ef",
   "metadata": {},
   "source": [
    "Apartado 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d223dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    WITH viajes_franja AS (\n",
    "        SELECT z.Zone AS pickup_zone,\n",
    "        HOUR(t.tpep_pickup_datetime) AS hour, \n",
    "        CASE \n",
    "            WHEN hour BETWEEN 5 AND 11 THEN 'mañana'\n",
    "            WHEN hour BETWEEN 12 AND 17 THEN 'tarde'\n",
    "            WHEN hour BETWEEN 18 AND 23 THEN 'noche'\n",
    "            ELSE 'madrugada'\n",
    "            END \n",
    "        AS franja\n",
    "        FROM yellow_trips t\n",
    "        JOIN taxi_zones z ON t.PULocationID = z.LocationID\n",
    "    )\n",
    "    SELECT pickup_zone, \n",
    "    franja,\n",
    "    COUNT(*) AS num_trips\n",
    "    FROM viajes_franja\n",
    "    GROUP BY pickup_zone, franja\n",
    "    ORDER BY num_trips DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1db201",
   "metadata": {},
   "source": [
    "Apartado 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f1164",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT z.Zone AS pickup_zone, ROUND(SUM(total_amount), 2) AS total_income\n",
    "    FROM yellow_trips t\n",
    "    JOIN taxi_zones z\n",
    "    ON t.PULocationID = z.LocationID\n",
    "    GROUP BY z.Zone\n",
    "    HAVING count(*) > 10000\n",
    "    ORDER BY total_income DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2353e1",
   "metadata": {},
   "source": [
    "Apartado 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fef997",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT z.Zone AS dropoff_zone, ROUND(STDDEV(t.tip_amount),2) as tip_var\n",
    "    FROM yellow_trips t\n",
    "    JOIN taxi_zones z\n",
    "    ON t.DOLocationID = z.LocationID\n",
    "    GROUP BY z.Zone\n",
    "    ORDER BY tip_var DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad81c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
